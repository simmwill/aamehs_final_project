---
title: "PCA Code"
author: "Will Simmons"
date: "3/20/2020"
output: html_document
---

## PCA Code - Epi Machine Learning

```{r}
install_github("vqv/ggbiplot")
library(ggbiplot)
```


### Step 1: Determine if scaling is necessary

```{r scale}
#Obtain and compare means and standard deviations across features. na.rm removes the missings
colMeans(bc.data.features, na.rm=TRUE)
apply(bc.data.features, 2, sd, na.rm=TRUE)

#some difference in means and mitoses is different than others. So decide to center and scale

```

### Step 2: Conduct the Principal Components Analysis
The function prcomp() will center and scale the variables and then identify the principal components

```{r pca}

bc.pca<-prcomp( ~., data=bc.data.features, center=TRUE, scale=TRUE, na.action=na.omit)

#Can compare sds used to scale with the sds above to ensure they are close.
bc.pca$scale

#view results of pca. Note the first three components are needed to explain at least 75% of the variance
summary(bc.pca)
bc.pca$rotation

ggbiplot(bc.pca)

ggbiplot(bc.pca, choices=c(2,3))

```

## PCR Code - Data Science II


We fit the PCR model using the function `pcr()`.

```{r}
library(pls)

set.seed(2)
pcr.mod <- pcr(Salary~., 
               data = Hitters[trRows,],
               scale = TRUE,                ## pcr - need to scale, automatically centers (glmnet - scale default)
               validation = "CV")

summary(pcr.mod)

validationplot(pcr.mod, val.type="MSEP", legendpos = "topright") ## 18 components provides lowest MSEPredicted
  ## usually focus on CV error (MSEP/RMSEP) vs. variance explained


cv.mse <- RMSEP(pcr.mod)
ncomp.cv <- which.min(cv.mse$val[1,,])-1   ## -1 because there is intercept as first term - gives index of what we want
ncomp.cv

predy2.pcr <- predict(pcr.mod, newdata = Hitters[-trRows,], 
                      ncomp = ncomp.cv) ## specify optimal number of values - defined above from PCR CV MSEP
# test MSE
mse(y2, predy2.pcr)
```
